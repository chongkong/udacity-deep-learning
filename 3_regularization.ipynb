{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": false,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in _notmist.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "    dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "    # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "    labels = (np.arange(num_labels) == labels[:, None]).astype(np.float32)\n",
    "    return dataset, labels\n",
    "\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "            / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "image_size = 28 * 28\n",
    "label_size = 10\n",
    "\n",
    "\n",
    "class BaseNN(object):\n",
    "    def __init__(self, hidden_layer_sizes, sgd_batch_size, alpha, num_steps):\n",
    "        self.layer_sizes = [image_size] + hidden_layer_sizes + [label_size]\n",
    "        self.sgd_batch_size = sgd_batch_size\n",
    "        self.alpha = alpha\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "        self.graph = tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "            self.tf_train_dataset = tf.placeholder(tf.float32, shape=(sgd_batch_size, image_size))\n",
    "            self.tf_train_labels = tf.placeholder(tf.float32, shape=(sgd_batch_size, label_size))\n",
    "            self.tf_valid_dataset = tf.constant(valid_dataset)\n",
    "            self.tf_test_dataset = tf.constant(test_dataset)\n",
    "\n",
    "            self.weights = [\n",
    "                tf.Variable(tf.truncated_normal([self.layer_sizes[i], self.layer_sizes[i + 1]]))\n",
    "                for i in range(len(self.layer_sizes) - 1)]\n",
    "            self.biases = [\n",
    "                tf.Variable(tf.zeros([self.layer_sizes[i + 1]]))\n",
    "                for i in range(len(self.layer_sizes) - 1)]\n",
    "\n",
    "            logits = self.forward_prop_train(self.tf_train_dataset)\n",
    "            self.loss = self.calculate_loss(logits, self.tf_train_labels)\n",
    "            self.optimizer = tf.train.GradientDescentOptimizer(alpha).minimize(self.loss)\n",
    "\n",
    "            self.train_prediction = tf.nn.softmax(logits)\n",
    "            self.valid_prediction = tf.nn.softmax(self.forward_prop(self.tf_valid_dataset))\n",
    "            self.test_prediction = tf.nn.softmax(self.forward_prop(self.tf_test_dataset))\n",
    "\n",
    "    def forward_prop(self, tf_dataset):\n",
    "        res = tf_dataset\n",
    "        for i in range(len(self.weights)):\n",
    "            res = tf.nn.relu(res) if i > 0 else res\n",
    "            res = tf.matmul(res, self.weights[i]) + self.biases[i]\n",
    "        return res\n",
    "\n",
    "    def forward_prop_train(self, tf_dataset):\n",
    "        return self.forward_prop(tf_dataset)\n",
    "\n",
    "    def calculate_loss(self, logits, labels):\n",
    "        return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits, labels))\n",
    "\n",
    "    def fit(self, train_dataset, train_labels, log_every=500):\n",
    "        with tf.Session(graph=self.graph) as session:\n",
    "            tf.initialize_all_variables().run()\n",
    "            print('Initialized')\n",
    "            \n",
    "            start_time = time.time()\n",
    "\n",
    "            for step in range(self.num_steps):\n",
    "                random_indices = np.random.choice(\n",
    "                    train_dataset.shape[0], self.sgd_batch_size)\n",
    "                batch_data = train_dataset[random_indices]\n",
    "                batch_labels = train_labels[random_indices]\n",
    "\n",
    "                _, l, predictions = session.run(\n",
    "                    [self.optimizer, self.loss, self.train_prediction],\n",
    "                    feed_dict={\n",
    "                        self.tf_train_dataset: batch_data,\n",
    "                        self.tf_train_labels: batch_labels})\n",
    "\n",
    "                if (step % log_every == 0):\n",
    "                    elapsed_sec = int((time.time() - start_time) * 1000) / 1000.0\n",
    "                    print(\"Elapsed seconds: {}\".format(elapsed_sec))\n",
    "                    print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "                    print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "                    print(\"Validation accuracy: %.1f%%\" % accuracy(self.valid_prediction.eval(), valid_labels))\n",
    "            print(\"Test accuracy: %.1f%%\" % accuracy(self.test_prediction.eval(), test_labels))\n",
    "\n",
    "\n",
    "class L2LossNN(BaseNN):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.beta = kwargs.pop('beta')\n",
    "        super(L2LossNN, self).__init__(*args, **kwargs)\n",
    "    \n",
    "    def calculate_loss(self, logits, labels):\n",
    "        return tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits, labels) +\n",
    "            self.beta * tf.add_n([tf.nn.l2_loss(w) for w in self.weights + self.biases]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 288.164062\n",
      "Minibatch accuracy: 6.2%\n",
      "Validation accuracy: 32.2%\n",
      "Minibatch loss at step 500: 50.046463\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 1000: 29.446426\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 1500: 17.567398\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 2000: 10.677494\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.6%\n",
      "Minibatch loss at step 2500: 6.784433\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.0%\n",
      "Minibatch loss at step 3000: 4.206826\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 3500: 2.705393\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 86.4%\n",
      "Minibatch loss at step 4000: 1.865380\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 4500: 1.306390\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 5000: 0.884554\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 87.7%\n",
      "Minibatch loss at step 5500: 0.909795\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.7%\n",
      "Minibatch loss at step 6000: 0.694114\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 6500: 0.572708\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.3%\n",
      "Minibatch loss at step 7000: 0.407042\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 7500: 0.484905\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 88.0%\n",
      "Minibatch loss at step 8000: 0.487028\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 8500: 0.579990\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 9000: 0.510244\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.3%\n",
      "Minibatch loss at step 9500: 0.488776\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 10000: 0.340494\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 88.3%\n",
      "Test accuracy: 94.2%\n"
     ]
    }
   ],
   "source": [
    "L2LossNN(\n",
    "    hidden_layer_sizes=[256], \n",
    "    sgd_batch_size=128,\n",
    "    alpha=0.5, \n",
    "    beta=0.001, \n",
    "    num_steps=10001\n",
    ").fit(train_dataset, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 774.489807\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 23.1%\n",
      "Minibatch loss at step 1500: 64.914047\n",
      "Minibatch accuracy: 33.6%\n",
      "Validation accuracy: 35.0%\n",
      "Minibatch loss at step 3000: 47.833633\n",
      "Minibatch accuracy: 57.8%\n",
      "Validation accuracy: 54.8%\n",
      "Minibatch loss at step 4500: 35.786533\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 61.3%\n",
      "Minibatch loss at step 6000: 26.739397\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 67.1%\n",
      "Minibatch loss at step 7500: 19.662354\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 74.3%\n",
      "Minibatch loss at step 9000: 14.706854\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 10500: 10.824858\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 12000: 8.275635\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 13500: 6.082581\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 85.1%\n",
      "Minibatch loss at step 15000: 4.679677\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 85.3%\n",
      "Minibatch loss at step 16500: 3.522124\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 85.8%\n",
      "Minibatch loss at step 18000: 2.912477\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 86.0%\n",
      "Minibatch loss at step 19500: 2.126957\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 86.6%\n",
      "Minibatch loss at step 21000: 1.707841\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.2%\n",
      "Minibatch loss at step 22500: 1.386352\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 87.5%\n",
      "Minibatch loss at step 24000: 1.089219\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.8%\n",
      "Minibatch loss at step 25500: 0.961479\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 87.9%\n",
      "Minibatch loss at step 27000: 0.761147\n",
      "Minibatch accuracy: 91.4%\n",
      "Validation accuracy: 88.2%\n",
      "Minibatch loss at step 28500: 0.745571\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 89.0%\n",
      "Minibatch loss at step 30000: 0.580694\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 89.0%\n",
      "Test accuracy: 94.5%\n"
     ]
    }
   ],
   "source": [
    "L2LossNN(\n",
    "    hidden_layer_sizes=[256, 64], \n",
    "    sgd_batch_size=128, \n",
    "    alpha=0.1, \n",
    "    beta=0.001, \n",
    "    num_steps=30001\n",
    ").fit(train_dataset, train_labels, log_every=1500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 161.214417\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 34.4%\n",
      "Minibatch loss at step 200: 0.399056\n",
      "Minibatch accuracy: 97.7%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 400: 0.002355\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 600: 3.052499\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 800: 0.004029\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.4%\n",
      "Minibatch loss at step 1000: 0.000009\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1200: 0.106549\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.2%\n",
      "Minibatch loss at step 1400: 2.994856\n",
      "Minibatch accuracy: 99.2%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 1600: 0.000206\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 1800: 0.000001\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.1%\n",
      "Minibatch loss at step 2000: 0.000053\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.0%\n",
      "Test accuracy: 84.2%\n"
     ]
    }
   ],
   "source": [
    "# No regularization with only 3000 samples; heavily overfitted\n",
    "\n",
    "L2LossNN(\n",
    "    hidden_layer_sizes=[256], \n",
    "    sgd_batch_size=128,\n",
    "    alpha=0.5, \n",
    "    beta=0, \n",
    "    num_steps=2001\n",
    ").fit(train_dataset[:3000], train_labels[:3000], log_every=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 949.289307\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 31.1%\n",
      "Minibatch loss at step 500: 5.648594\n",
      "Minibatch accuracy: 98.4%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 1000: 0.618355\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 82.3%\n",
      "Minibatch loss at step 1500: 0.567008\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 82.2%\n",
      "Minibatch loss at step 2000: 0.618557\n",
      "Minibatch accuracy: 92.2%\n",
      "Validation accuracy: 82.1%\n",
      "Minibatch loss at step 2500: 0.574018\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 3000: 0.535748\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 82.6%\n",
      "Minibatch loss at step 3500: 0.563654\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 4000: 0.621553\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 82.4%\n",
      "Minibatch loss at step 4500: 0.577981\n",
      "Minibatch accuracy: 94.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 5000: 0.559099\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 81.5%\n",
      "Test accuracy: 88.0%\n"
     ]
    }
   ],
   "source": [
    "# With some regularization; less overfitted than above one\n",
    "\n",
    "L2LossNN(\n",
    "    hidden_layer_sizes=[256], \n",
    "    sgd_batch_size=128,\n",
    "    alpha=0.5, \n",
    "    beta=0.01,\n",
    "    num_steps=5001\n",
    ").fit(train_dataset[:3000], train_labels[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DropoutNN(BaseNN):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.keep_prob = kwargs.pop('keep_prob')\n",
    "        super(DropoutNN, self).__init__(*args, **kwargs)\n",
    "\n",
    "    def forward_prop_train(self, tf_dataset):\n",
    "        res = tf_dataset\n",
    "        for i in range(len(self.weights)):\n",
    "            res = tf.nn.dropout(tf.nn.relu(res), self.keep_prob) if i > 0 else res\n",
    "            res = tf.matmul(res, self.weights[i]) + self.biases[i]\n",
    "        return res\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 234.625916\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 31.4%\n",
      "Minibatch loss at step 500: 2.816261\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1000: 1.083063\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 1500: 3.001185\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 2000: 0.058738\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 2500: 0.336682\n",
      "Minibatch accuracy: 93.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 3000: 0.080011\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 3500: 0.532647\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 4000: 0.484350\n",
      "Minibatch accuracy: 96.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 4500: 0.109667\n",
      "Minibatch accuracy: 96.9%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 5000: 0.140859\n",
      "Minibatch accuracy: 95.3%\n",
      "Validation accuracy: 79.7%\n",
      "Test accuracy: 86.8%\n"
     ]
    }
   ],
   "source": [
    "DropoutNN(\n",
    "    hidden_layer_sizes=[256], \n",
    "    sgd_batch_size=128,\n",
    "    alpha=0.5, \n",
    "    keep_prob=0.5,\n",
    "    num_steps=5001\n",
    ").fit(train_dataset[:3000], train_labels[:3000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Elapsed seconds: 0.025\n",
      "Minibatch loss at step 0: 3815.986572\n",
      "Minibatch accuracy: 10.2%\n",
      "Validation accuracy: 22.9%\n",
      "Elapsed seconds: 66.899\n",
      "Minibatch loss at step 5000: 1.619660\n",
      "Minibatch accuracy: 37.5%\n",
      "Validation accuracy: 39.6%\n",
      "Elapsed seconds: 141.138\n",
      "Minibatch loss at step 10000: 1.670287\n",
      "Minibatch accuracy: 34.4%\n",
      "Validation accuracy: 49.1%\n",
      "Elapsed seconds: 218.036\n",
      "Minibatch loss at step 15000: 1.569534\n",
      "Minibatch accuracy: 43.0%\n",
      "Validation accuracy: 53.0%\n",
      "Elapsed seconds: 302.218\n",
      "Minibatch loss at step 20000: 1.289515\n",
      "Minibatch accuracy: 50.0%\n",
      "Validation accuracy: 55.8%\n",
      "Elapsed seconds: 388.268\n",
      "Minibatch loss at step 25000: 1.114318\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 58.6%\n",
      "Elapsed seconds: 475.081\n",
      "Minibatch loss at step 30000: 1.151361\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 61.5%\n",
      "Elapsed seconds: 558.479\n",
      "Minibatch loss at step 35000: 1.160618\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 62.4%\n",
      "Elapsed seconds: 646.313\n",
      "Minibatch loss at step 40000: 0.876479\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 64.5%\n",
      "Elapsed seconds: 732.948\n",
      "Minibatch loss at step 45000: 1.003394\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 64.7%\n",
      "Elapsed seconds: 815.305\n",
      "Minibatch loss at step 50000: 0.905402\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 66.0%\n",
      "Elapsed seconds: 908.799\n",
      "Minibatch loss at step 55000: 1.401891\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 67.2%\n",
      "Elapsed seconds: 996.463\n",
      "Minibatch loss at step 60000: 1.188077\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 67.2%\n",
      "Elapsed seconds: 1082.212\n",
      "Minibatch loss at step 65000: 1.033831\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 69.4%\n",
      "Elapsed seconds: 1167.336\n",
      "Minibatch loss at step 70000: 0.766832\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 67.9%\n",
      "Elapsed seconds: 1254.18\n",
      "Minibatch loss at step 75000: 0.857537\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 68.6%\n",
      "Elapsed seconds: 1344.565\n",
      "Minibatch loss at step 80000: 0.942588\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 69.7%\n",
      "Elapsed seconds: 1433.278\n",
      "Minibatch loss at step 85000: 0.872999\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 70.5%\n",
      "Elapsed seconds: 1521.63\n",
      "Minibatch loss at step 90000: 0.818065\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 70.7%\n",
      "Elapsed seconds: 1607.722\n",
      "Minibatch loss at step 95000: 0.883089\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 69.7%\n",
      "Elapsed seconds: 1695.929\n",
      "Minibatch loss at step 100000: 0.713274\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 70.2%\n",
      "Elapsed seconds: 1783.164\n",
      "Minibatch loss at step 105000: 1.277944\n",
      "Minibatch accuracy: 61.7%\n",
      "Validation accuracy: 71.6%\n",
      "Elapsed seconds: 1872.738\n",
      "Minibatch loss at step 110000: 1.607621\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 71.7%\n",
      "Elapsed seconds: 1960.11\n",
      "Minibatch loss at step 115000: 1.052822\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 71.7%\n",
      "Elapsed seconds: 2050.293\n",
      "Minibatch loss at step 120000: 0.715046\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 72.7%\n",
      "Elapsed seconds: 2141.101\n",
      "Minibatch loss at step 125000: 0.671206\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 73.1%\n",
      "Elapsed seconds: 2235.991\n",
      "Minibatch loss at step 130000: 1.051661\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 73.2%\n",
      "Elapsed seconds: 2330.312\n",
      "Minibatch loss at step 135000: 0.731726\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 72.8%\n",
      "Elapsed seconds: 2425.693\n",
      "Minibatch loss at step 140000: 0.782788\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 73.2%\n",
      "Elapsed seconds: 2517.865\n",
      "Minibatch loss at step 145000: 0.852513\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 73.0%\n",
      "Elapsed seconds: 2614.414\n",
      "Minibatch loss at step 150000: 0.659894\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 74.5%\n",
      "Elapsed seconds: 2714.586\n",
      "Minibatch loss at step 155000: 1.061925\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 72.2%\n",
      "Elapsed seconds: 2814.954\n",
      "Minibatch loss at step 160000: 0.911615\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 74.8%\n",
      "Elapsed seconds: 2911.529\n",
      "Minibatch loss at step 165000: 0.988120\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 74.7%\n",
      "Elapsed seconds: 3010.706\n",
      "Minibatch loss at step 170000: 0.866468\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 75.4%\n",
      "Elapsed seconds: 3107.352\n",
      "Minibatch loss at step 175000: 0.667408\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 75.1%\n",
      "Elapsed seconds: 3202.649\n",
      "Minibatch loss at step 180000: 0.907759\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 71.8%\n",
      "Elapsed seconds: 3295.047\n",
      "Minibatch loss at step 185000: 0.785994\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 75.3%\n",
      "Elapsed seconds: 3391.91\n",
      "Minibatch loss at step 190000: 0.585455\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 76.1%\n",
      "Elapsed seconds: 3488.698\n",
      "Minibatch loss at step 195000: 1.288388\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 75.8%\n",
      "Elapsed seconds: 3587.647\n",
      "Minibatch loss at step 200000: 0.562156\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 75.8%\n",
      "Elapsed seconds: 3688.279\n",
      "Minibatch loss at step 205000: 0.631355\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 75.4%\n",
      "Elapsed seconds: 3787.589\n",
      "Minibatch loss at step 210000: 0.561346\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 75.8%\n",
      "Elapsed seconds: 3886.037\n",
      "Minibatch loss at step 215000: 0.608607\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.3%\n",
      "Elapsed seconds: 3984.902\n",
      "Minibatch loss at step 220000: 0.618632\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.5%\n",
      "Elapsed seconds: 4084.174\n",
      "Minibatch loss at step 225000: 0.772217\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 76.6%\n",
      "Elapsed seconds: 4183.8\n",
      "Minibatch loss at step 230000: 0.684561\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 76.7%\n",
      "Elapsed seconds: 4277.802\n",
      "Minibatch loss at step 235000: 0.757844\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 77.2%\n",
      "Elapsed seconds: 4370.144\n",
      "Minibatch loss at step 240000: 0.615599\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 77.0%\n",
      "Elapsed seconds: 4462.951\n",
      "Minibatch loss at step 245000: 0.947115\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 77.2%\n",
      "Elapsed seconds: 4552.888\n",
      "Minibatch loss at step 250000: 0.755310\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 76.5%\n",
      "Elapsed seconds: 4644.722\n",
      "Minibatch loss at step 255000: 0.715304\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 76.6%\n",
      "Elapsed seconds: 4745.063\n",
      "Minibatch loss at step 260000: 0.633529\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 77.7%\n",
      "Elapsed seconds: 4843.551\n",
      "Minibatch loss at step 265000: 0.840556\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 77.3%\n",
      "Elapsed seconds: 4942.537\n",
      "Minibatch loss at step 270000: 0.735023\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 78.2%\n",
      "Elapsed seconds: 5042.923\n",
      "Minibatch loss at step 275000: 0.762636\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 78.5%\n",
      "Elapsed seconds: 5143.968\n",
      "Minibatch loss at step 280000: 0.645357\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.3%\n",
      "Elapsed seconds: 5243.313\n",
      "Minibatch loss at step 285000: 0.499433\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.4%\n",
      "Elapsed seconds: 5340.73\n",
      "Minibatch loss at step 290000: 0.642810\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.7%\n",
      "Elapsed seconds: 5436.775\n",
      "Minibatch loss at step 295000: 0.808010\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 77.3%\n",
      "Elapsed seconds: 5530.368\n",
      "Minibatch loss at step 300000: 0.613319\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 78.3%\n",
      "Elapsed seconds: 5632.183\n",
      "Minibatch loss at step 305000: 0.689565\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 78.0%\n",
      "Elapsed seconds: 5734.531\n",
      "Minibatch loss at step 310000: 0.574992\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.3%\n",
      "Elapsed seconds: 5830.523\n",
      "Minibatch loss at step 315000: 0.585016\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.4%\n",
      "Elapsed seconds: 5927.891\n",
      "Minibatch loss at step 320000: 0.541425\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.0%\n",
      "Elapsed seconds: 6029.315\n",
      "Minibatch loss at step 325000: 0.643515\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.1%\n",
      "Elapsed seconds: 6130.019\n",
      "Minibatch loss at step 330000: 0.605041\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.4%\n",
      "Elapsed seconds: 6229.989\n",
      "Minibatch loss at step 335000: 0.521407\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 79.3%\n",
      "Elapsed seconds: 6328.6\n",
      "Minibatch loss at step 340000: 0.657881\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 76.7%\n",
      "Elapsed seconds: 6427.099\n",
      "Minibatch loss at step 345000: 0.719384\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.3%\n",
      "Elapsed seconds: 6529.767\n",
      "Minibatch loss at step 350000: 0.581742\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 79.4%\n",
      "Elapsed seconds: 6628.989\n",
      "Minibatch loss at step 355000: 0.487754\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.0%\n",
      "Elapsed seconds: 6731.692\n",
      "Minibatch loss at step 360000: 0.719365\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 79.9%\n",
      "Elapsed seconds: 6831.381\n",
      "Minibatch loss at step 365000: 0.818433\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.1%\n",
      "Elapsed seconds: 6928.624\n",
      "Minibatch loss at step 370000: 0.519076\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.7%\n",
      "Elapsed seconds: 7026.639\n",
      "Minibatch loss at step 375000: 0.634744\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.7%\n",
      "Elapsed seconds: 7126.066\n",
      "Minibatch loss at step 380000: 0.657441\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.1%\n",
      "Elapsed seconds: 7223.472\n",
      "Minibatch loss at step 385000: 0.572079\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.3%\n",
      "Elapsed seconds: 7320.677\n",
      "Minibatch loss at step 390000: 0.542977\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.8%\n",
      "Elapsed seconds: 7422.383\n",
      "Minibatch loss at step 395000: 0.540051\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.9%\n",
      "Elapsed seconds: 7519.028\n",
      "Minibatch loss at step 400000: 0.562918\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.1%\n",
      "Elapsed seconds: 7621.874\n",
      "Minibatch loss at step 405000: 0.510590\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.5%\n",
      "Elapsed seconds: 7723.467\n",
      "Minibatch loss at step 410000: 0.745156\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.5%\n",
      "Elapsed seconds: 7824.265\n",
      "Minibatch loss at step 415000: 0.559980\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.0%\n",
      "Elapsed seconds: 7924.333\n",
      "Minibatch loss at step 420000: 0.532369\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.8%\n",
      "Elapsed seconds: 8024.094\n",
      "Minibatch loss at step 425000: 0.617353\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.0%\n",
      "Elapsed seconds: 8121.711\n",
      "Minibatch loss at step 430000: 0.481266\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.6%\n",
      "Elapsed seconds: 8218.955\n",
      "Minibatch loss at step 435000: 0.692748\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.3%\n",
      "Elapsed seconds: 8321.05\n",
      "Minibatch loss at step 440000: 0.584375\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.7%\n",
      "Elapsed seconds: 8420.986\n",
      "Minibatch loss at step 445000: 0.546459\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.4%\n",
      "Elapsed seconds: 8520.262\n",
      "Minibatch loss at step 450000: 0.664978\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.0%\n",
      "Elapsed seconds: 8617.263\n",
      "Minibatch loss at step 455000: 0.676110\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.1%\n",
      "Elapsed seconds: 8711.676\n",
      "Minibatch loss at step 460000: 0.624701\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Elapsed seconds: 8813.367\n",
      "Minibatch loss at step 465000: 0.576256\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.4%\n",
      "Elapsed seconds: 8911.806\n",
      "Minibatch loss at step 470000: 0.690586\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.3%\n",
      "Elapsed seconds: 9012.619\n",
      "Minibatch loss at step 475000: 0.439530\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.4%\n",
      "Elapsed seconds: 9111.756\n",
      "Minibatch loss at step 480000: 0.526689\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.6%\n",
      "Elapsed seconds: 9209.994\n",
      "Minibatch loss at step 485000: 0.523379\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.1%\n",
      "Elapsed seconds: 9304.559\n",
      "Minibatch loss at step 490000: 0.575402\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Elapsed seconds: 9401.664\n",
      "Minibatch loss at step 495000: 0.708935\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Elapsed seconds: 9502.88\n",
      "Minibatch loss at step 500000: 0.788631\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.2%\n",
      "Elapsed seconds: 9605.381\n",
      "Minibatch loss at step 505000: 0.643410\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.6%\n",
      "Elapsed seconds: 9703.382\n",
      "Minibatch loss at step 510000: 0.478842\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.7%\n",
      "Elapsed seconds: 9800.282\n",
      "Minibatch loss at step 515000: 0.595206\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 76.8%\n",
      "Elapsed seconds: 9894.641\n",
      "Minibatch loss at step 520000: 0.628699\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.7%\n",
      "Elapsed seconds: 9995.471\n",
      "Minibatch loss at step 525000: 0.684952\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.8%\n",
      "Elapsed seconds: 10095.893\n",
      "Minibatch loss at step 530000: 0.518214\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.0%\n",
      "Elapsed seconds: 10195.054\n",
      "Minibatch loss at step 535000: 0.575591\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.5%\n",
      "Elapsed seconds: 10290.367\n",
      "Minibatch loss at step 540000: 0.616837\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.7%\n",
      "Elapsed seconds: 10390.247\n",
      "Minibatch loss at step 545000: 0.550672\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.7%\n",
      "Elapsed seconds: 10489.463\n",
      "Minibatch loss at step 550000: 0.522881\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.6%\n",
      "Elapsed seconds: 10590.322\n",
      "Minibatch loss at step 555000: 0.438483\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.8%\n",
      "Elapsed seconds: 10688.596\n",
      "Minibatch loss at step 560000: 0.574287\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.2%\n",
      "Elapsed seconds: 10783.166\n",
      "Minibatch loss at step 565000: 0.603690\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.8%\n",
      "Elapsed seconds: 10883.51\n",
      "Minibatch loss at step 570000: 0.525000\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.8%\n",
      "Elapsed seconds: 10982.711\n",
      "Minibatch loss at step 575000: 0.499842\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.3%\n",
      "Elapsed seconds: 11076.902\n",
      "Minibatch loss at step 580000: 0.432445\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 82.0%\n",
      "Elapsed seconds: 11172.769\n",
      "Minibatch loss at step 585000: 0.613167\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 82.0%\n",
      "Elapsed seconds: 11268.085\n",
      "Minibatch loss at step 590000: 0.517203\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.2%\n",
      "Elapsed seconds: 11363.123\n",
      "Minibatch loss at step 595000: 0.651572\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 82.3%\n",
      "Elapsed seconds: 11462.331\n",
      "Minibatch loss at step 600000: 0.506999\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.9%\n",
      "Elapsed seconds: 11560.04\n",
      "Minibatch loss at step 605000: 0.400367\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.2%\n",
      "Elapsed seconds: 11654.852\n",
      "Minibatch loss at step 610000: 0.504450\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "Elapsed seconds: 11751.004\n",
      "Minibatch loss at step 615000: 0.461510\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.5%\n",
      "Elapsed seconds: 11846.004\n",
      "Minibatch loss at step 620000: 0.384949\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.1%\n",
      "Elapsed seconds: 11941.166\n",
      "Minibatch loss at step 625000: 0.516674\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.8%\n",
      "Elapsed seconds: 12035.571\n",
      "Minibatch loss at step 630000: 1.804276\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 82.0%\n",
      "Elapsed seconds: 12135.085\n",
      "Minibatch loss at step 635000: 0.307227\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 82.0%\n",
      "Elapsed seconds: 12235.31\n",
      "Minibatch loss at step 640000: 0.281287\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 82.4%\n",
      "Elapsed seconds: 12333.023\n",
      "Minibatch loss at step 645000: 0.848905\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.5%\n",
      "Elapsed seconds: 12431.868\n",
      "Minibatch loss at step 650000: 0.499651\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 82.8%\n",
      "Elapsed seconds: 12530.647\n",
      "Minibatch loss at step 655000: 0.507390\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.8%\n",
      "Elapsed seconds: 12628.992\n",
      "Minibatch loss at step 660000: 0.701121\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 82.9%\n",
      "Elapsed seconds: 12729.904\n",
      "Minibatch loss at step 665000: 0.573591\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 82.8%\n",
      "Elapsed seconds: 12826.38\n",
      "Minibatch loss at step 670000: 0.406602\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 82.5%\n",
      "Elapsed seconds: 12926.087\n",
      "Minibatch loss at step 675000: 0.537205\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 82.6%\n",
      "Elapsed seconds: 13022.655\n",
      "Minibatch loss at step 680000: 0.638285\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 82.9%\n",
      "Elapsed seconds: 13119.393\n",
      "Minibatch loss at step 685000: 0.397289\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 82.8%\n",
      "Elapsed seconds: 13218.565\n",
      "Minibatch loss at step 690000: 0.339231\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 82.9%\n",
      "Elapsed seconds: 13317.084\n",
      "Minibatch loss at step 695000: 0.473344\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.0%\n",
      "Elapsed seconds: 13411.895\n",
      "Minibatch loss at step 700000: 0.784991\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 83.0%\n",
      "Elapsed seconds: 13508.848\n",
      "Minibatch loss at step 705000: 0.606469\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 83.1%\n",
      "Elapsed seconds: 13610.311\n",
      "Minibatch loss at step 710000: 0.568991\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 82.8%\n",
      "Elapsed seconds: 13712.446\n",
      "Minibatch loss at step 715000: 0.499883\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 82.9%\n",
      "Elapsed seconds: 13808.119\n",
      "Minibatch loss at step 720000: 0.492236\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.1%\n",
      "Elapsed seconds: 13903.883\n",
      "Minibatch loss at step 725000: 0.597895\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 83.5%\n",
      "Elapsed seconds: 14001.297\n",
      "Minibatch loss at step 730000: 0.484269\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.0%\n",
      "Elapsed seconds: 14102.667\n",
      "Minibatch loss at step 735000: 0.578272\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 83.3%\n",
      "Elapsed seconds: 14203.622\n",
      "Minibatch loss at step 740000: 0.686076\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 83.3%\n",
      "Elapsed seconds: 14302.484\n",
      "Minibatch loss at step 745000: 0.608660\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 83.3%\n",
      "Elapsed seconds: 14401.774\n",
      "Minibatch loss at step 750000: 0.677792\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 82.8%\n",
      "Elapsed seconds: 14503.066\n",
      "Minibatch loss at step 755000: 0.520218\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 83.5%\n",
      "Elapsed seconds: 14598.435\n",
      "Minibatch loss at step 760000: 0.626586\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 83.4%\n",
      "Elapsed seconds: 14696.49\n",
      "Minibatch loss at step 765000: 0.379250\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 83.1%\n",
      "Elapsed seconds: 14794.867\n",
      "Minibatch loss at step 770000: 0.564450\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 83.2%\n",
      "Elapsed seconds: 14896.029\n",
      "Minibatch loss at step 775000: 0.357419\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 83.4%\n",
      "Elapsed seconds: 14998.478\n",
      "Minibatch loss at step 780000: 0.456997\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 83.1%\n",
      "Elapsed seconds: 15093.457\n",
      "Minibatch loss at step 785000: 0.382155\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 83.3%\n",
      "Elapsed seconds: 15188.784\n",
      "Minibatch loss at step 790000: 0.475259\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 15280.155\n",
      "Minibatch loss at step 795000: 0.460572\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.3%\n",
      "Elapsed seconds: 15374.345\n",
      "Minibatch loss at step 800000: 0.392016\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 83.4%\n",
      "Elapsed seconds: 15471.825\n",
      "Minibatch loss at step 805000: 0.344813\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.2%\n",
      "Elapsed seconds: 15573.208\n",
      "Minibatch loss at step 810000: 0.469087\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 83.6%\n",
      "Elapsed seconds: 15669.327\n",
      "Minibatch loss at step 815000: 0.419320\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 15765.227\n",
      "Minibatch loss at step 820000: 0.338283\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 15860.067\n",
      "Minibatch loss at step 825000: 0.371140\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 15958.047\n",
      "Minibatch loss at step 830000: 0.569039\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 83.6%\n",
      "Elapsed seconds: 16058.027\n",
      "Minibatch loss at step 835000: 0.475644\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 16154.839\n",
      "Minibatch loss at step 840000: 0.526891\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.4%\n",
      "Elapsed seconds: 16252.779\n",
      "Minibatch loss at step 845000: 0.567222\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 83.5%\n",
      "Elapsed seconds: 16354.308\n",
      "Minibatch loss at step 850000: 0.445122\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 83.8%\n",
      "Elapsed seconds: 16451.634\n",
      "Minibatch loss at step 855000: 0.303882\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 16547.878\n",
      "Minibatch loss at step 860000: 0.491736\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 83.8%\n",
      "Elapsed seconds: 16647.485\n",
      "Minibatch loss at step 865000: 0.462730\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 16748.169\n",
      "Minibatch loss at step 870000: 0.531160\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 83.6%\n",
      "Elapsed seconds: 16844.173\n",
      "Minibatch loss at step 875000: 0.353802\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 16942.269\n",
      "Minibatch loss at step 880000: 0.301110\n",
      "Minibatch accuracy: 89.8%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 17040.854\n",
      "Minibatch loss at step 885000: 0.438531\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.0%\n",
      "Elapsed seconds: 17141.409\n",
      "Minibatch loss at step 890000: 0.521735\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.1%\n",
      "Elapsed seconds: 17238.293\n",
      "Minibatch loss at step 895000: 0.577019\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 84.0%\n",
      "Elapsed seconds: 17336.952\n",
      "Minibatch loss at step 900000: 0.462272\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.9%\n",
      "Elapsed seconds: 17432.96\n",
      "Minibatch loss at step 905000: 0.367592\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.1%\n",
      "Elapsed seconds: 17530.087\n",
      "Minibatch loss at step 910000: 0.620272\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 83.9%\n",
      "Elapsed seconds: 17628.141\n",
      "Minibatch loss at step 915000: 0.406721\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.0%\n",
      "Elapsed seconds: 17724.402\n",
      "Minibatch loss at step 920000: 0.471255\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 84.1%\n",
      "Elapsed seconds: 17822.514\n",
      "Minibatch loss at step 925000: 0.386849\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 83.9%\n",
      "Elapsed seconds: 17921.588\n",
      "Minibatch loss at step 930000: 0.437624\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 83.6%\n",
      "Elapsed seconds: 18018.422\n",
      "Minibatch loss at step 935000: 0.440949\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.0%\n",
      "Elapsed seconds: 18110.475\n",
      "Minibatch loss at step 940000: 0.266698\n",
      "Minibatch accuracy: 90.6%\n",
      "Validation accuracy: 84.2%\n",
      "Elapsed seconds: 18203.623\n",
      "Minibatch loss at step 945000: 0.468420\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.3%\n",
      "Elapsed seconds: 18300.043\n",
      "Minibatch loss at step 950000: 0.503062\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 84.2%\n",
      "Elapsed seconds: 18397.9\n",
      "Minibatch loss at step 955000: 0.416321\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.2%\n",
      "Elapsed seconds: 18492.561\n",
      "Minibatch loss at step 960000: 0.331926\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 84.4%\n",
      "Elapsed seconds: 18589.352\n",
      "Minibatch loss at step 965000: 0.445237\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 84.3%\n",
      "Elapsed seconds: 18685.297\n",
      "Minibatch loss at step 970000: 0.468297\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 84.4%\n",
      "Elapsed seconds: 18779.289\n",
      "Minibatch loss at step 975000: 0.409203\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 84.4%\n",
      "Elapsed seconds: 18868.305\n",
      "Minibatch loss at step 980000: 0.519146\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 83.5%\n",
      "Elapsed seconds: 18964.16\n",
      "Minibatch loss at step 985000: 0.479732\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 19058.846\n",
      "Minibatch loss at step 990000: 0.348502\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 83.7%\n",
      "Elapsed seconds: 19153.109\n",
      "Minibatch loss at step 995000: 0.305071\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 84.1%\n",
      "Elapsed seconds: 19246.18\n",
      "Minibatch loss at step 1000000: 0.403393\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 84.2%\n",
      "Test accuracy: 91.1%\n"
     ]
    }
   ],
   "source": [
    "DropoutNN(\n",
    "    hidden_layer_sizes=[1024, 256], \n",
    "    sgd_batch_size=128,\n",
    "    alpha=0.05,\n",
    "    keep_prob=0.9,\n",
    "    num_steps=1000001\n",
    ").fit(train_dataset, train_labels, log_every=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
